{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "720f2fe4-e4f5-400b-a3e1-418c99b09784",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eea855-bce8-4319-9d41-c84bc1f08c6b",
   "metadata": {},
   "source": [
    "Wir werden hier einen ersten Ansatz für die *Textverarbeitung* in Python kennen lernen, wobei wir die Bilbiothek `scikit-learn` einsetzen werden. Es bedarf in diesem Zusammenhang einer gründlichen Vorverarbeitung der Daten und der *Merkmalsextraktion* ([feature extraction](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)). Man hat es ferner mit sehr *dünn besetzten Matrizen* (engl. **sparse matrices**) zu tun.\n",
    "\n",
    "Ziel ist es, Beleidigungen in Diskussionforen zu erkennen. Der zugehörige Datensatz ist im Ordner `data/text_classification` vorhanden.\n",
    "Er wurde vom [Daten-Repository](https://github.com/ipython-books/cookbook-data) des [Cookbook](https://ipython-books.github.io/)s heruntergeladen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26d9fc-747d-4fec-acc7-29d9903cf8cd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52ce39a-8c88-4635-85fb-a436efc7f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1662c24-ce25-4575-ae05-4e8a98b1dce1",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3121e386-ba03-414d-a374-bfaf378fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/text_classification/troll.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fde2a5-5f01-43ba-a6a3-e15c2ec3cac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "407e6ab0-081f-4915-812c-42aa95d9f13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3947, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec04f8-db15-423c-9900-40f0d6cf190b",
   "metadata": {},
   "source": [
    "Definition der *Merkmalsmatrix* $\\mathbf{X}$ und der *Klassen* (Labels) $\\mathbf{y}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dc4e58f-bf87-4f17-9d1a-6ef6ec9a834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Insult']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92c52e-7700-4da7-9a9d-8c93ba09eb2c",
   "metadata": {},
   "source": [
    "Die Merkmalsmatrix hingegen ist deutlich schwieriger zu erhalten. `scikit-learn` kann nur mit Zahlen in Matrizen etwas anfangen, so dass man den Text also in eine Matrix umwandeln muss. Diese **Datenvorverarbeitung** (also die *Data Preparation* gemäß [CRISP-DM](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)) geschieht meist in zwei Schritten:\n",
    "1. **Tokenizing**: Man extrahiert ein **Vokabular**, d.h. eine Liste von Wörtern, die im Text (in unserem Fall: in den Kommentaren) benutzt wurden\n",
    "2. **Counting:** Anschließend \"zählt\" man in jedem Datensatz (auch: *Dokument*), wie oft das jeweilige Wort darin vorkommt. Da es im Allgemeinen sehr viele Wörter gibt und nur die wenigsten davon in einem bestimmten Datensatz (bei uns: in einem Kommentar) wirklich benutzt werden, führt dies zu einer Matrix, die hauptsächlich Nullen enthält (also dünn besetzt ist).\n",
    "\n",
    "Das gesamte Verfahren wird auch als **Bag of Words** bezeichnet. Mit Hilfe von `scikit-learn` brauchen wir nur zwei Zeilen Code hierfür. Es kommt zum \"Zählen\" das [Tf-idf](https://de.wikipedia.org/wiki/Tf-idf-Ma%C3%9F) Verfahren zum Einsatz, mit dessen Hilfe zu häufig vorkommende Wörter (\"the\", \"and, etc.) adäquat behandelt werden können. Durch *Tf-idf* wird das Vokabular normalisiert, so dass Wörtern, welche in einer großen Anzahl der Datensätze vorkommen, weniger Gewicht zukommt, als solchen, welche nur in einer geringen Anzahl der Datensätze vorkommen und daher *spezieller* sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5fe2d3-ffff-48cc-8905-4d01c6599074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 3947 Kommentaren sind 16469 verschiedene Wörter\n"
     ]
    }
   ],
   "source": [
    "co = text.CountVectorizer() # Tokenizing + Counting\n",
    "X = co.fit_transform(df['Comment']) # Transformation aller Kommentare\n",
    "print(f'In {X.shape[0]} Kommentaren sind {X.shape[1]} verschiedene Wörter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3f9f3db-b385-42f7-a7b1-39817fbd72ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c7c6b12-5c1e-4b9a-a095-70f978c6a945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 16397),\n",
       " ('fuck', 5434),\n",
       " ('your', 16405),\n",
       " ('dad', 3409),\n",
       " ('really', 11568),\n",
       " ('don', 4075),\n",
       " ('understand', 14793),\n",
       " ('point', 10754),\n",
       " ('xa0', 15720),\n",
       " ('it', 7048)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f744b4df-fe5f-4646-b1a2-27884843771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Merkmalsmatrix hat ~0.15% von Null verschiedene Einträge.\n"
     ]
    }
   ],
   "source": [
    "print(\"Die Merkmalsmatrix hat ~{0:.2f}% von Null verschiedene Einträge.\".format(\n",
    "          100 * X.nnz / float(X.shape[0] * X.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0fb213-3460-404e-974a-2be921a3d392",
   "metadata": {},
   "source": [
    "Aufteilung in **Trainings-** und **Testdaten**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ea83f3-23c7-4836-b693-71ce039e503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=.2, random_state = 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7533ce4-1536-4b02-9510-babdfd315464",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8a5a1-e981-497f-b3e5-9c74895c0659",
   "metadata": {},
   "source": [
    "Als Naive-Bayes-Klassifikator verwenden wir den [Multinomialen Naive Bayes Klassifikator](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_na%C3%AFve_Bayes), welcher die Häufigkeit der Worte als ganzzahligen Wert betrachtet. In der Praxis funktioniert das Modell aber auch mit der Tf-idf-Vektorisierung. Zusätzlich wird eine *Glättung* mit Hilfe eines Parameters $\\alpha$ durchgeführt (eine Erklärung des Ansatzes findet man bei der [Stanford University](https://nlp.stanford.edu/courses/cs224n/2001/gruffydd/smoothing.html) und wir kennen ihn als Laplace-Schätzer ...). Weitere Naive-Bayes-Modelle in `scikit-learn` finden sich [hier](https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28a38591-5cf4-426d-b60a-3f1a0f26614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "bnb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e7501-95e2-4f04-a0b2-3d84ebedb676",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a043f76b-e82a-482d-9f9b-8d04db519b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Trefferquote beträgt ca. 77.85%\n"
     ]
    }
   ],
   "source": [
    "print(f'Die Trefferquote beträgt ca. {round(100*bnb.score(X_test, y_test),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bac8b8b-4156-4278-ae78-7f10597f901a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wörter mit beleidigender Assoziation: \n",
      " ['you' 'the' 'to' 'your' 'and' 'are' 'of' 'that' 'it' 'is' 'in' 'like'\n",
      " 'xa0' 'have' 'on' 'for' 'not' 're' 'just' 'be' 'as' 'this' 'all' 'fuck'\n",
      " 'get' 'so' 'with' 'what' 'an']\n"
     ]
    }
   ],
   "source": [
    "insult_class_prob_sorted = bnb.best_estimator_.feature_log_prob_[1, :].argsort()\n",
    "\n",
    "word_list_insult = np.take(X_vec.get_feature_names_out(), insult_class_prob_sorted[:-30:-1])\n",
    "\n",
    "print(f'Wörter mit beleidigender Assoziation: \\n {word_list_insult}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3be8d9-512b-4dc7-a20b-e805617bab30",
   "metadata": {},
   "source": [
    "Test mit eigenen Beispielen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34085438-feaf-44be-8f3e-13220d923d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(bnb.predict(co.transform([\n",
    "    \"You are absolutely right.\",\n",
    "    \"This is beyond moronic.\",\n",
    "    \"LOL\"\n",
    "    ])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
